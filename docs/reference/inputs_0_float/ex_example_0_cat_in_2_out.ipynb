{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da093956",
   "metadata": {},
   "source": [
    "# example_0_cat_in_2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\"This file demonstrates benchmarking with 0 categorical inputs and 2 output variables.\n",
    "\n",
    "It benchmarks a single Python operation configuration to showcase output variations\n",
    "using simulated performance data to illustrate how benchmarking works with fixed inputs.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import bencher as bch\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "class PythonOperations0CatBenchmark(bch.ParametrizedSweep):\n",
    "    \"\"\"Example class for benchmarking with no categorical variables.\n",
    "\n",
    "    This class demonstrates how to structure a benchmark with fixed inputs\n",
    "    and multiple output metrics. It uses simulated performance data that follows realistic\n",
    "    patterns while being deterministic and reproducible.\n",
    "    \"\"\"\n",
    "\n",
    "    # All inputs are fixed (list data structure, read operation, medium size)\n",
    "\n",
    "    execution_time = bch.ResultVar(units=\"ms\", doc=\"Execution time in milliseconds\")\n",
    "    memory_peak = bch.ResultVar(units=\"KB\", doc=\"Peak memory usage in kilobytes\")\n",
    "\n",
    "    def __call__(self, **kwargs) -> dict:\n",
    "        \"\"\"Execute the benchmark for the given set of parameters.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Parameters to update before executing\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing the benchmark results\n",
    "        \"\"\"\n",
    "        self.update_params_from_kwargs(**kwargs)\n",
    "\n",
    "        # Base values for list read operation on medium data\n",
    "        base_time = 28.0  # ms\n",
    "        base_memory = 960.0  # KB\n",
    "\n",
    "        # Add significant variance to show distribution of results\n",
    "        # even with fixed inputs\n",
    "        self.execution_time = base_time * random.gauss(0.75, 1.25)\n",
    "        self.memory_peak = base_memory * random.gauss(0.80, 1.20)\n",
    "\n",
    "        return super().__call__(**kwargs)\n",
    "\n",
    "\n",
    "def example_0_cat_in_2_out(\n",
    "    run_cfg: bch.BenchRunCfg = None, report: bch.BenchReport = None\n",
    ") -> bch.Bench:\n",
    "    \"\"\"This example demonstrates benchmarking with no categorical variables and multiple output metrics.\n",
    "\n",
    "    It creates a synthetic benchmark that simulates performance variations when repeatedly running\n",
    "    the same operation (list read operation on medium data). This example shows that even with\n",
    "    fixed inputs, repeated benchmark runs produce variations in performance metrics.\n",
    "\n",
    "    Args:\n",
    "        run_cfg: Configuration for the benchmark run\n",
    "        report: Report to append the results to\n",
    "\n",
    "    Returns:\n",
    "        bch.Bench: The benchmark object\n",
    "    \"\"\"\n",
    "\n",
    "    if run_cfg is None:\n",
    "        run_cfg = bch.BenchRunCfg()\n",
    "    run_cfg.repeats = 100  # More repeats to show distribution\n",
    "    bench = PythonOperations0CatBenchmark().to_bench(run_cfg, report)\n",
    "    bench.plot_sweep(\n",
    "        title=\"Python List Read Operation Performance (Fixed Inputs)\",\n",
    "        description=\"Distribution of execution time and peak memory usage across multiple runs\",\n",
    "        post_description=\"\"\"\n",
    "        This benchmark illustrates how performance metrics vary even with fixed inputs.\n",
    "        \n",
    "        Key observations:\n",
    "        - Each run uses the same configuration: list data structure, read operation, medium data size\n",
    "        - Despite identical inputs, performance metrics show natural variations\n",
    "        - This variance simulates real-world system fluctuations that occur in benchmarking\n",
    "        - With no categorical variables, the benchmark helps establish baseline performance\n",
    "          distribution for a single configuration\n",
    "        \"\"\",\n",
    "    )\n",
    "    return bench\n",
    "\n",
    "\n",
    "bench = example_0_cat_in_2_out(bch.BenchRunCfg(repeats=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b29476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "bench.get_result().to_auto_plots()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
