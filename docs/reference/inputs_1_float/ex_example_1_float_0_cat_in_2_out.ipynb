{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194f208f",
   "metadata": {},
   "source": [
    "# example_1_float_0_cat_in_2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\"This file demonstrates benchmarking with 1 float input and 0 categorical inputs with 2 output variables.\n",
    "\n",
    "It benchmarks a single algorithm configuration across different problem sizes to show\n",
    "how performance scales, using simulated performance data to illustrate benchmarking basics.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import math\n",
    "import bencher as bch\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "class Algorithm0CatBenchmark(bch.ParametrizedSweep):\n",
    "    \"\"\"Example class for benchmarking algorithm performance with just problem size.\n",
    "\n",
    "    This class demonstrates how to structure a benchmark with one float parameter and\n",
    "    no categorical parameters, producing multiple output metrics. It uses simulated\n",
    "    performance data that follows realistic patterns while being deterministic.\n",
    "    \"\"\"\n",
    "\n",
    "    # Float input parameter\n",
    "    problem_size = bch.FloatSweep(default=100, bounds=[1, 100], doc=\"Size of the problem to solve\")\n",
    "\n",
    "    # Using fixed \"iterative\" algorithm, \"array\" data structure, and \"basic\" optimization level\n",
    "\n",
    "    # Output metrics\n",
    "    execution_time = bch.ResultVar(units=\"ms\", doc=\"Execution time in milliseconds\")\n",
    "    memory_usage = bch.ResultVar(units=\"MB\", doc=\"Memory usage in megabytes\")\n",
    "\n",
    "    def __call__(self, **kwargs) -> dict:\n",
    "        \"\"\"Execute the benchmark for the given set of parameters.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Parameters to update before executing\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing the benchmark results\n",
    "        \"\"\"\n",
    "        self.update_params_from_kwargs(**kwargs)\n",
    "\n",
    "        # Base values for calculation\n",
    "        base_time = 1.0  # ms\n",
    "        base_memory = 0.1  # MB\n",
    "\n",
    "        # Size factor (non-linear relationship with problem size)\n",
    "        size_factor_time = math.log10(self.problem_size) ** 1.5\n",
    "        size_factor_memory = math.sqrt(self.problem_size) / 10\n",
    "\n",
    "        # Fixed \"iterative\" algorithm factors (from previous example)\n",
    "        algo_time_factor = 0.8  # Iterative is faster\n",
    "        algo_memory_factor = 0.7  # Iterative uses less memory\n",
    "\n",
    "        # Fixed \"array\" data structure factors (from previous example)\n",
    "        ds_time_factor = 0.9  # Arrays have faster access\n",
    "        ds_memory_factor = 1.1  # Arrays use slightly more contiguous memory\n",
    "\n",
    "        # Fixed \"basic\" optimization level factors (from previous example)\n",
    "        opt_time_factor = 1.0\n",
    "        opt_memory_factor = 1.0\n",
    "\n",
    "        # Calculate final metrics with some random variation\n",
    "        time_multiplier = (\n",
    "            algo_time_factor * ds_time_factor * opt_time_factor * random.uniform(0.9, 1.1)\n",
    "        )\n",
    "        memory_multiplier = (\n",
    "            algo_memory_factor * ds_memory_factor * opt_memory_factor * random.uniform(0.95, 1.05)\n",
    "        )\n",
    "\n",
    "        self.execution_time = base_time * size_factor_time * time_multiplier\n",
    "        self.memory_usage = base_memory * size_factor_memory * memory_multiplier\n",
    "\n",
    "        return super().__call__(**kwargs)\n",
    "\n",
    "\n",
    "def example_1_float_0_cat_in_2_out(\n",
    "    run_cfg: bch.BenchRunCfg = None, report: bch.BenchReport = None\n",
    ") -> bch.Bench:\n",
    "    \"\"\"This example demonstrates benchmarking with 1 float input and 0 categorical inputs.\n",
    "\n",
    "    It creates a synthetic benchmark that simulates performance characteristics of an\n",
    "    algorithm configuration across different problem sizes. The benchmark uses fixed\n",
    "    \"iterative\" algorithm, \"array\" data structure, and \"basic\" optimization level,\n",
    "    producing realistic patterns of execution time and memory usage without actually\n",
    "    executing real algorithms.\n",
    "\n",
    "    Args:\n",
    "        run_cfg: Configuration for the benchmark run\n",
    "        report: Report to append the results to\n",
    "\n",
    "    Returns:\n",
    "        bch.Bench: The benchmark object\n",
    "    \"\"\"\n",
    "\n",
    "    if run_cfg is None:\n",
    "        run_cfg = bch.BenchRunCfg()\n",
    "    run_cfg.repeats = 5  # Slightly more repeats to show variance\n",
    "    bench = Algorithm0CatBenchmark().to_bench(run_cfg, report)\n",
    "    bench.plot_sweep(\n",
    "        title=\"Algorithm Performance Benchmark (1 Float, 0 Categorical Variables)\",\n",
    "        description=\"Analyzing how execution time and memory usage scale with problem size\",\n",
    "        post_description=\"\"\"\n",
    "        This benchmark illustrates how algorithm performance scales with problem size.\n",
    "        \n",
    "        Key observations:\n",
    "        - Execution time increases non-linearly with problem size (logarithmic relationship)\n",
    "        - Memory usage scales more gradually (square root relationship)\n",
    "        - All tests were performed with an iterative algorithm on array data structure with basic optimization\n",
    "        - Small variations in performance metrics simulate the natural fluctuations seen in real benchmarks\n",
    "        - This type of benchmark is useful for understanding scaling properties of a single algorithm configuration\n",
    "        \"\"\",\n",
    "    )\n",
    "    return bench\n",
    "\n",
    "\n",
    "bench = example_1_float_0_cat_in_2_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "bench.report.pane"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
